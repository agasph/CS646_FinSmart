{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import voyageai\n",
    "import torch\n",
    "from time import sleep\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "TASKS = ['TATQA', 'FinQA', 'ConvFinQA', 'MultiHiertt']\n",
    "MODEL_NAME = \"voyage-3\"\n",
    "BATCH_SIZE = 32\n",
    "DELAY_BETWEEN_BATCHES = 0.1\n",
    "LOG_FILE = \"process.log\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "vo_client = voyageai.Client(api_key=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(task, attribute, version, client):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a given task and attribute (e.g., corpus or queries).\n",
    "    \"\"\"\n",
    "    file_suffix = \"_convert\" if version == \"convert\" else \"\"\n",
    "    input_path = f\"./data/{task}_{attribute}{file_suffix}.csv\"\n",
    "    output_file = f\"{task}_{attribute}{file_suffix}.json\"\n",
    "    output_path = f\"./{MODEL_NAME}/embed/{output_file}\"\n",
    "\n",
    "    data = pd.read_csv(input_path).dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "    embeddings = {}\n",
    "\n",
    "    for start_idx in tqdm(range(0, len(data), BATCH_SIZE), desc=f\"Processing {attribute} - {version}\", leave=False):\n",
    "        batch = data.iloc[start_idx:start_idx + BATCH_SIZE]\n",
    "        batch_ids = batch[\"_id\"].tolist()\n",
    "        batch_texts = (\n",
    "            batch[\"convert_text\"].tolist() if version == \"convert\" else batch[\"text\"].tolist()\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            embed_type = \"query\" if attribute == \"queries\" else \"document\"\n",
    "            result = client.embed(batch_texts, model=MODEL_NAME, input_type=embed_type).embeddings\n",
    "            embeddings.update(dict(zip(batch_ids, result)))\n",
    "        except Exception as error:\n",
    "            logging.error(f\"Error in task '{task}' - {attribute}: Batch starting at {start_idx}: {error}\")\n",
    "        \n",
    "        sleep(DELAY_BETWEEN_BATCHES)\n",
    "\n",
    "    with open(output_path, \"w\") as file:\n",
    "        json.dump(embeddings, file)\n",
    "    logging.info(f\"Embeddings saved for {task} - {attribute} ({version}) at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all tasks\n",
    "for task in TASKS:\n",
    "    for attribute in [\"corpus\", \"queries\"]:\n",
    "        versions = [\"convert\", \"original\"] if attribute == \"corpus\" else [\"original\"]\n",
    "        for version in versions:\n",
    "            generate_embeddings(task, attribute, version, vo_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two tensors.\"\"\"\n",
    "    normalized_a = torch.nn.functional.normalize(a, p=2, dim=1)\n",
    "    normalized_b = torch.nn.functional.normalize(b, p=2, dim=1)\n",
    "    return torch.mm(normalized_a, normalized_b.T)\n",
    "\n",
    "def calculate_scores(task):\n",
    "    \"\"\"Compute similarity scores and save top matches.\"\"\"\n",
    "    with open(f\"./{MODEL_NAME}/embed/{task}_queries.json\", \"r\") as q_file:\n",
    "        query_data = json.load(q_file)\n",
    "    \n",
    "    with open(f\"./{MODEL_NAME}/embed/{task}_corpus_convert.json\", \"r\") as c_file:\n",
    "        corpus_data = json.load(c_file)\n",
    "    \n",
    "    query_ids = list(query_data.keys())\n",
    "    corpus_ids = list(corpus_data.keys())\n",
    "    \n",
    "    query_embeddings = torch.tensor([query_data[qid] for qid in query_ids])\n",
    "    corpus_embeddings = torch.tensor([corpus_data[cid] for cid in corpus_ids])\n",
    "\n",
    "    similarity_matrix = cosine_similarity(query_embeddings, corpus_embeddings)\n",
    "    top_k = 500 if task not in ['FinQABench', 'FinanceBench'] else 50\n",
    "\n",
    "    matches = {}\n",
    "    for idx, query_id in enumerate(query_ids):\n",
    "        top_scores, top_indices = torch.topk(similarity_matrix[idx], top_k)\n",
    "        matches[query_id] = {\n",
    "            corpus_ids[i]: top_scores[j].item() for j, i in enumerate(top_indices)\n",
    "        }\n",
    "\n",
    "    output_path = f\"./{MODEL_NAME}/{task}_convert.json\"\n",
    "    with open(output_path, \"w\") as output_file:\n",
    "        json.dump(matches, output_file)\n",
    "    logging.info(f\"Similarity scores saved for {task} at {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate scores for all tasks\n",
    "for task in TASKS:\n",
    "    calculate_scores(task)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
