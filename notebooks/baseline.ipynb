{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/financerag/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "# --------------------------------------\n",
    "# Import required libraries for document retrieval, reranking, and logging setup.\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER\n",
    "\n",
    "# Setup basic logging configuration to show info level messages.\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n",
      "INFO:financerag.common.loader:Loaded 13867 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'ADBE20230004', 'title': 'ADBE OVERVIEW', 'text': 'Adobe is a global technology company with a mission to change the world through personalized digital experiences. For over four decades, Adobe’s innovations have transformed how individuals, teams, businesses, enterprises, institutions, and governments engage and interact across all types of media. Our products, services and solutions are used around the world to imagine, create, manage, deliver, measure, optimize and engage with content across surfaces and fuel digital experiences. We have a diverse user base that includes consumers, communicators, creative professionals, developers, students, small and medium businesses and enterprises. We are also empowering creators by putting the power of artificial intelligence (“AI”) in their hands, and doing so in ways we believe are responsible. Our products and services help unleash creativity, accelerate document productivity and power businesses in a digital world.'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 216 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q00001', 'text': 'What are the service and product offerings from Microsoft'}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize FinDER Task\n",
    "# --------------------------\n",
    "# In this baseline example, we are using the FinDER task, one of the seven available tasks in this project.\n",
    "# If you want to use a different task, for example, 'OtherTask', you can change the task initialization as follows:\n",
    "#\n",
    "# Example:\n",
    "# from financerag.tasks import OtherTask\n",
    "# finder_task = OtherTask()\n",
    "#\n",
    "# For this baseline, we proceed with FinDER.\n",
    "finder_task = FinDER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initialize DenseRetriever model\n",
    "# -------------------------------------\n",
    "# Initialize the retrieval model using SentenceTransformers. This model will be responsible\n",
    "# for encoding both the queries and documents into embeddings.\n",
    "#\n",
    "# You can replace 'intfloat/e5-large-v2' with any other model supported by SentenceTransformers.\n",
    "# For example: 'BAAI/bge-large-en-v1.5', 'Linq-AI-Research/Linq-Embed-Mistral', etc.\n",
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BM25Okapi.__init__() missing 1 required positional argument: 'corpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrank_bm25\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BM25Okapi\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinancerag\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrieval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BM25Retriever\n\u001b[0;32m----> 4\u001b[0m retrieval_model \u001b[38;5;241m=\u001b[39m BM25Retriever(model\u001b[38;5;241m=\u001b[39m\u001b[43mBM25Okapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: BM25Okapi.__init__() missing 1 required positional argument: 'corpus'"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from financerag.retrieval import BM25Retriever\n",
    "\n",
    "retrieval_model = BM25Retriever(model=BM25Okapi())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Loads a JSONL file and returns a list of dictionaries.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "        List[dict]: A list of JSON objects.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'title', 'text'],\n",
       "    num_rows: 13867\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Loading a specific subset (i.e. FinDER) and a split (corpus, queries)\n",
    "corpus = load_dataset(\"Linq-AI-Research/FinanceRAG\", \"FinDER\", split=\"corpus\")\n",
    "corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BM25Processor\n",
    "from nltk.tokenize import word_tokenize\n",
    "from financerag.retrieval import BM25Processor\n",
    "processor = BM25Processor(tokenizer=word_tokenize)\n",
    "# Tokenize and prepare the corpus\n",
    "tokenized_corpus = processor.build_corpus(corpus)\n",
    "\n",
    "# # Initialize BM25 model\n",
    "from rank_bm25 import BM25Okapi\n",
    "bm25_model = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Encoding queries...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BM25Okapi' object has no attribute 'encode_queries'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Perform retrieval\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Use the model to retrieve relevant documents for given queries.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m retrieval_model \u001b[38;5;241m=\u001b[39m DenseRetrieval(\n\u001b[1;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mbm25_model\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m retrieval_result \u001b[38;5;241m=\u001b[39m \u001b[43mfinder_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretrieval_model\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Print a portion of the retrieval results to verify the output.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrieved results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(retrieval_result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m queries. Here\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms an example of the top 5 documents for the first query:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Studies/Sphurti/Information Retrieval/Project/FinanceRAG/financerag/tasks/BaseTask.py:133\u001b[0m, in \u001b[0;36mBaseTask.retrieve\u001b[0;34m(self, retriever, top_k, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData has not been loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve_results\n",
      "File \u001b[0;32m~/Studies/Sphurti/Information Retrieval/Project/FinanceRAG/financerag/retrieval/dense.py:158\u001b[0m, in \u001b[0;36mDenseRetrieval.retrieve\u001b[0;34m(self, corpus, queries, top_k, score_function, return_sorted, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m {qid: {} \u001b[38;5;28;01mfor\u001b[39;00m qid \u001b[38;5;129;01min\u001b[39;00m query_ids}\n\u001b[1;32m    157\u001b[0m query_texts \u001b[38;5;241m=\u001b[39m [queries[qid] \u001b[38;5;28;01mfor\u001b[39;00m qid \u001b[38;5;129;01min\u001b[39;00m queries]\n\u001b[0;32m--> 158\u001b[0m query_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_queries\u001b[49m(\n\u001b[1;32m    159\u001b[0m     query_texts, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    160\u001b[0m )\n\u001b[1;32m    162\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorting corpus by document length...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m sorted_corpus_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    164\u001b[0m     corpus,\n\u001b[1;32m    165\u001b[0m     key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m k: \u001b[38;5;28mlen\u001b[39m(corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m corpus[k]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    166\u001b[0m     reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    167\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BM25Okapi' object has no attribute 'encode_queries'"
     ]
    }
   ],
   "source": [
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/sajayudhay/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 'ADBE20230004', 'title': 'ADBE OVERVIEW', 'text': 'Adobe is a global technology company with a mission to change the world through personalized digital experiences. For over four decades, Adobe’s innovations have transformed how individuals, teams, businesses, enterprises, institutions, and governments engage and interact across all types of media. Our products, services and solutions are used around the world to imagine, create, manage, deliver, measure, optimize and engage with content across surfaces and fuel digital experiences. We have a diverse user base that includes consumers, communicators, creative professionals, developers, students, small and medium businesses and enterprises. We are also empowering creators by putting the power of artificial intelligence (“AI”) in their hands, and doing so in ways we believe are responsible. Our products and services help unleash creativity, accelerate document productivity and power businesses in a digital world.'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.bm25:Tokenizing queries with lower cases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the service and product offerings from microsoft\n",
      "msft segment breakdown\n",
      "who are microsoft`s key customers?\n",
      "what is microsoft`s business model\n",
      "msft capex commitment\n",
      "which recent m&a activities has microsoft been involved in\n",
      "how much revenue does microsoft generate from contracts with customers?\n",
      "msft remaining performance obligation\n",
      "adobe subsidiaries of trademarks\n",
      "adbe share repurchase\n",
      "fully diluted shares outstanding adbe\n",
      "who are the members of adobe`s management team\n",
      "adbe rpo\n",
      "adbe kpi\n",
      "how are coupang`s kpis?\"\n",
      "coupang segment margin\n",
      "cpng capital expenditure\n",
      "cpng any recent m&a activities\n",
      "when did coupang`s farfetch consolidation start\n",
      "what is flc, and how is its revenue recognized by coupang\n",
      "when did new flc contract begin cpng\n",
      "cpng free cash flow\n",
      "class of shares cpng\n",
      "any highlights from linde`s 2023 earnings result\n",
      "linde segment breakdown\n",
      "linde shareholder return\n",
      "asset divestitures linde\n",
      "what is the total number of leases held by linde\n",
      "linde outstanding share\n",
      "the top 3 risks faced by linde\n",
      "linde`s geographical coverage\n",
      "which items were taken into account to derive adjusted ebitda compared to ebitda for linde\n",
      "one-off expenses of linde occurred in 2023\n",
      "why did linde`s working capital increase\n",
      "how much is available for oracle stock repurchases\n",
      "oracle`s equity investments\n",
      "orcl m&a\n",
      "oracle`s contractual obligations\n",
      "why did oracle`s net cash used for investing activities change by over 80%\n",
      "which cost item represents the highest percentage of oracle`s sales\n",
      "orcl segment breakdown\n",
      "updates on oracle`s headcount\n",
      "oracle`s dividend payout\n",
      "any meaningful ramp to address ai capacity/datacenter constraints orcl\n",
      "nvidia`s end market\n",
      "nvidia 5yr cumulative total return\n",
      "percentage of total revenue accounted for by nvidia`s largest customer\n",
      "any other concentration risks observed from nvidia`s financials?\n",
      "what drove the improvement in the gross profit margin nvda\n",
      "p&g business model\n",
      "what percentage of total revenue does the p&g`s largest customer account for\n",
      "current number of employees at p&g and % yoy growth\n",
      "how did war between russia and ukraine impact p&g business\n",
      "p&g cybersecurity related risks\n",
      "who among the management had the longest tenure? p&g\n",
      "p&g any updates on share repurchase plan?\n",
      "how many consecutive years has p&g increased its dividend?\n",
      "by what percentage did the p&g`s dividend increase this year\n",
      "p&g`s ticker\n",
      "p&g org structure overview\n",
      "how many product categories does p&g have\n",
      "what are the major brands for fem care in p&g\n",
      "strategic direction of p&g\n",
      "why did net earnings decrease despite increase of sales/op p&g\n",
      "p&g what does the ratio of adjusted free cash flow to net earnings imply?\n",
      "which factor contributed more significantly to the gross margin improvement of p&g: price increases or quantity increases?\n",
      "capex during the fiscal year ended in jun 2023 and where it was spent p&g\n",
      "did p&g acquire any businesses in 2023?\n",
      "did p&g raise any debts during the fiscal year ended in jun 2023\n",
      "what is the total amount of cash and cash equivalents procter & gamble (p&g) has as of the fiscal year ended in jun 2023\n",
      "p&g`s credit rating?\n",
      "what was the yoy organic growth % of beauty segment of p&g\n",
      "what is a measure for p&g to determine dividends, share repurchases, acquisitions and other discretionary investments\n",
      "how many fleet does dal own\n",
      "ratio of owned: finance lease: operating lease based on operating aircraft fleet dal\n",
      "what percentage of endeavor`s shares does delta own?\n",
      "when is the scheduled delivery date for the dal a350?\n",
      "which region showed highest % growth of delta in passenger revenue? and what was the main driver?\n",
      "any updates on dal and amex partnership\n",
      "which operating expense represents the highest percentage of dal`s sales\n",
      "how did the fuel price impact the 2023 financials of delta air lines\n",
      "dal capex during the fiscal year ended in jun 2023 and where it was spent\n",
      "dal 2024 capex guidance\n",
      "what is the estimated cost for the new york-laguardia redevelopment dal\n",
      "when did dal`s quarterly dividend start all over again?\n",
      "how much was the delta¡¯s aggregate current and noncurrent loyalty program deferred revenue balance as of fy 2023\n",
      "what is the useful life for aircraft dal\n",
      "where does dal recognize advertising costs\n",
      "how many vehicles did tsla deliver in 2023?\n",
      "were there any one-off items reported in tesla 2023?\n",
      "capex in 2023 tsla\n",
      "tsla capex guidance in 2024\n",
      "where does tsla produce its cybertruck\n",
      "tsla inventory breakdown as of 2023\n",
      "any recent litigation cases tesla\n",
      "tsla three-year historical depreciation expense\n",
      "how many outstanding shares tsla\n",
      "what is tsla`s mission?\n",
      "netflix paid membership updates\n",
      "does netflix still offer dvd-by-mail service\n",
      "netflix business model\n",
      "netflix any updates on total amount of content obligations\n",
      "content obligations in next 12 months netflix\n",
      "nflx 3 year historical advertising cost trend\n",
      "3 year streaming revenue trend of netflix\n",
      "what drove op margin improvement nflx\n",
      "which region showed the highest increase in paid net membership additions of netflix\n",
      "nflx any updates on share repurchase\n",
      "customer group that home depot serve\n",
      "home depot # of employee\n",
      "home depot retail strategy\n",
      "hd how many acquisitions happened in 2023?\n",
      "total amount of shareholder return in 2023 home depot\n",
      "any reasons for capex growth of hd\n",
      "home depot why did net sales decrease in 2023?\n",
      "updates on inventory level home depot\n",
      "net advertising expense over the past three years on an annual basis home depot\n",
      "hd net pp&e as of 2023\n",
      "company fiscal year appl\n",
      "when will apple vision pro launch?\n",
      "depreciation expense on pp&e over the past three years on an annual basis apple\n",
      "update on share repurchase of apple\n",
      "which region contributes the most to the revenue of appl?\n",
      "appl new product launch in 4q23\n",
      "sg&a % of rev in 2023 appl\n",
      "appl additional leases occurred in later part of 2023\n",
      "when was the most recent employee stock plan that apple announced?\n",
      "appl depreciation expense over the past three years on an annual basis\n",
      "amazon aws yoy growth in constant cuurency\n",
      "amazon 1q24 guidance\n",
      "amzn what are the components of fulfillment costs?\n",
      "2023 inventory valuation allowance of amzn\n",
      "total pp&e of amzn in 2023\n",
      "any updates on amazon prime video\n",
      "were there any share repurchases in 2023 amazon?\n",
      "amzn sbc expense occurred in 2023\n",
      "amazon revenue sources\n",
      "any comments on tech investment of amazon\n",
      "amazon par value\n",
      "potential/current competitors of amazon?\n",
      "when was amazon established?\n",
      "what is the total square footage of amazon`s international fulfillment centers, data centers, and other facilities?\n",
      "revenue recognition methodology of amazon from 3rd party seller\n",
      "when did 20:1 stock split happen in amzn\n",
      "describe how aws generate revenue\n",
      "amazon acquisitions in 2023?\n",
      "when was the current share repurchase program announced in amzn?\n",
      "amazon inventory management strategy\n",
      "why does meta use family metrics?\n",
      "meta family dap and map calculation methodology?\n",
      "any upddates on reality labs meta\n",
      "key investment areas in 2024 meta\n",
      "mgmt view on meta competitive landscape\n",
      "meta % yoy growth of foa revenue\n",
      "meta what is management`s outlook on the future drivers of ad revenue?\n",
      "has the sales volume of meta quest increased or decreased?\n",
      "any divestures in 2023 meta\n",
      "total number of employees of jnj\n",
      "gross amounts of patents and trademarks as of 2023 jnj\n",
      "what has been dps over the past 3 years jnj\n",
      "jnj diluted adj. avg. shares outstanding as of 2023 (include the unit as well)\n",
      "best selling drug in 2023 of johnson & johnson\n",
      "johnson & johnson investment in 2023\n",
      "jnj mgmt overview\n",
      "how much $ invested in jnj r&d as of 2023\n",
      "any advancements for its innovative medicine pipeline jnj\n",
      "jnj r&d expense % of revenue in 2023\n",
      "roe and rotce as of 2023 jp morgan\n",
      "credit provided for consumers as of 2023 jp morgan\n",
      "jp morgan markets revenue consist of what\n",
      "what are the components of principal transactions of jpm\n",
      "jpm acquisition in 2023\n",
      "competitors of jpm\n",
      "employee net addition in 2023 jpm\n",
      "why did lt debt increase in 2023 jp morgan\n",
      "jpm what drove strong performance of equity underwriting\n",
      "jp morgan segment breakdown\n",
      "visa company overview\n",
      "how does visa earn money\n",
      "visa acquisition in 2023\n",
      "who are visa`s electronic payment competitors\n",
      "how geopolitical factors can impact the visa business\n",
      "why did labor cost increase 17% yoy visa\n",
      "what has been the total amount of processed transactions by visa over the past 3 years, measured in billions?\n",
      "visa 2023 earning\n",
      "visa fintech related commentary\n",
      "unitedhealth group segment breakdown\n",
      "unitedhealth group what drove revenue increase in 2023\n",
      "company level op margin in 2023 unitedhealth\n",
      "unh roe as of 2023\n",
      "unh impact of cyber attack\n",
      "medical care ratio of unitedhealth group as of 2023\n",
      "any updates on brazil biz disposition of unitedhealth group\n",
      "what is management`s outlook of unitedhealth group on medical cost trends for 2024?\n",
      "what factors contributed to the significant increase in revenue of unh?\n",
      "dividend paid in 2023 unitedhealth\n",
      "what is alphabet`s stance on ai?\n",
      "primary revenue source of google services\n",
      "what potential threats to google search has the management identified?\n",
      "why did alphabet opex increase in 2023 vs. previous year\n",
      "alphabet when was the offer letter issued to ruth porat?\n",
      "capex guidance alphabet\n",
      "how is subscription revenue (e.g., youtube premium) recognized\n",
      "alphabet what has been the trend in advertising and promotional expenses over the past three years?\n",
      "google cloud rpo as of 2023 (approximate # is fine)\n",
      "how might changes to advertising policies and data privacy practices impact alphabet`s ads biz\n",
      "bnsf railroad freight volume\n",
      "who runs berkshire\n",
      "what is management`s perspective on the insurance business berkshire hathaway\n",
      "how is berkshire hathaway`s business segmented into its major divisions or operating units\n",
      "when will berkshire repurchase common stock?\n",
      "how many distinct insurance underwriting groups are there within berkshire\n",
      "what is the ticker symbol for berkshire hathaway`s class b shares?\n",
      "what is the largest operating segment of the berkshire hathaway in terms of % of total revenue, as of 2023\n",
      "source of invested assets of insurance business brk.a\n",
      "float as of 2023 brk\n",
      "Retrieved results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = AAPL20230240, Score = 21.499988903914545\n",
      "  Document 2: Document ID = AAPL20230021, Score = 21.4787740291409\n",
      "  Document 3: Document ID = UNH20230184, Score = 20.577153775101248\n",
      "  Document 4: Document ID = MSFT20230134, Score = 20.385077483690427\n",
      "  Document 5: Document ID = ORCL20230219, Score = 20.30521294271534\n"
     ]
    }
   ],
   "source": [
    "from financerag.retrieval import BM25Retriever\n",
    "\n",
    "# Step 4: Perform retrieval\n",
    "# ---------------------\n",
    "# Use the model to retrieve relevant documents for given queries.\n",
    "retrieval_model = BM25Retriever(model=bm25_model)\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")\n",
    "\n",
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: mps\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Initialize CrossEncoder Reranker\n",
    "# --------------------------------------\n",
    "# The CrossEncoder model will be used to rerank the retrieved documents based on relevance.\n",
    "#\n",
    "# You can replace 'cross-encoder/ms-marco-MiniLM-L-12-v2' with any other model supported by CrossEncoder.\n",
    "# For example: 'cross-encoder/ms-marco-TinyBERT-L-2', 'cross-encoder/stsb-roberta-large', etc.\n",
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n",
      "Batches: 100%|██████████| 675/675 [07:25<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230331, Score = 5.333600997924805\n",
      "  Document 2: Document ID = MSFT20230134, Score = 3.972005844116211\n",
      "  Document 3: Document ID = ORCL20230429, Score = 1.7133623361587524\n",
      "  Document 4: Document ID = ORCL20230003, Score = 0.6058417558670044\n",
      "  Document 5: Document ID = ORCL20230160, Score = 0.3706078827381134\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Perform reranking\n",
    "# -------------------------\n",
    "# Rerank the top 100 retrieved documents using the CrossEncoder model.\n",
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results/FinDER\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results/FinDER/results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results/FinDER/results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ./results/FinDER/results.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_21918/2167823414.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.0000\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.0060\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.0130\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.0000\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.0039\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.0065\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.0000\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.0078\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.0273\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.0000\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0031\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.0, 'NDCG@5': 0.00604, 'NDCG@10': 0.01302},\n",
       " {'MAP@1': 0.0, 'MAP@5': 0.00391, 'MAP@10': 0.00653},\n",
       " {'Recall@1': 0.0, 'Recall@5': 0.00781, 'Recall@10': 0.02734},\n",
       " {'P@1': 0.0, 'P@5': 0.00313, 'P@10': 0.00469})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the TSV file containing the 30% answer labels\n",
    "df = pd.read_csv('../data/FinDER_qrels.tsv', sep='\\t')\n",
    "\n",
    "# Convert the TSV data into a dictionary format for evaluation\n",
    "qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
    "\n",
    "# If the retrieval or reranking result is stored in the `results` variable\n",
    "# Evaluate the model on various metrics such as Recall, Precision, MAP, and nDCG\n",
    "finder_task.evaluate(qrels_dict, retrieval_result, [1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'NDCG@1': 0.0, 'NDCG@5': 0.00604, 'NDCG@10': 0.01302},\n",
    "#  {'MAP@1': 0.0, 'MAP@5': 0.00391, 'MAP@10': 0.00653},\n",
    "#  {'Recall@1': 0.0, 'Recall@5': 0.00781, 'Recall@10': 0.02734},\n",
    "#  {'P@1': 0.0, 'P@5': 0.00313, 'P@10': 0.00469})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'NDCG@1': 0.10938, 'NDCG@5': 0.14169, 'NDCG@10': 0.14634},\n",
    "#  {'MAP@1': 0.08203, 'MAP@5': 0.12467, 'MAP@10': 0.12797},\n",
    "#  {'Recall@1': 0.08203, 'Recall@5': 0.16406, 'Recall@10': 0.17578},\n",
    "#  {'P@1': 0.10938, 'P@5': 0.05, 'P@10': 0.02813})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ({'NDCG@1': 0.25, 'NDCG@5': 0.3363, 'NDCG@10': 0.36985},\n",
    "#  {'MAP@1': 0.21875, 'MAP@5': 0.30514, 'MAP@10': 0.32151},\n",
    "#  {'Recall@1': 0.21875, 'Recall@5': 0.39687, 'Recall@10': 0.48646},\n",
    "#  {'P@1': 0.25, 'P@5': 0.1125, 'P@10': 0.07188})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_18891/2997892314.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.2500\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.3363\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3699\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.2188\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.3051\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.3215\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.2188\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.3969\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.4865\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.2500\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.1125\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.25, 'NDCG@5': 0.3363, 'NDCG@10': 0.36985},\n",
       " {'MAP@1': 0.21875, 'MAP@5': 0.30514, 'MAP@10': 0.32151},\n",
       " {'Recall@1': 0.21875, 'Recall@5': 0.39687, 'Recall@10': 0.48646},\n",
       " {'P@1': 0.25, 'P@5': 0.1125, 'P@10': 0.07188})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the TSV file containing the 30% answer labels\n",
    "df = pd.read_csv('../data/FinDER_qrels.tsv', sep='\\t')\n",
    "\n",
    "# Convert the TSV data into a dictionary format for evaluation\n",
    "qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
    "\n",
    "# If the retrieval or reranking result is stored in the `results` variable\n",
    "# Evaluate the model on various metrics such as Recall, Precision, MAP, and nDCG\n",
    "finder_task.evaluate(qrels_dict, reranking_result, [1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financerag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
