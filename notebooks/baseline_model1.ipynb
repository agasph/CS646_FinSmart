{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.insert(0, str(Path(os.getcwd()).parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/financerag/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from financerag.retrieval import BM25Retriever, BM25Processor\n",
    "import financerag.tasks as tasks_module\n",
    "\n",
    "import importlib\n",
    "import inspect\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval = ['FinDER', 'FinQABench', 'FinanceBench', 'TATQA', 'FinQA', 'ConvFinQA', 'MultiHiertt']\n",
    "retrieval = ['FinQA', 'ConvFinQA', 'MultiHiertt']\n",
    "\n",
    "tabular_retrieval = ['TATQA', 'FinQA', 'ConvFinQA', 'MultiHiertt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './e5-large-v2'\n",
    "reranker_name = 'ms-marco-MiniLM-L-12-v2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def process_task(task_class, corpus_documents, output_dir, finder_task):\n",
    "    # Tokenize corpus\n",
    "\n",
    "    # processor = BM25Processor(tokenizer=tweet_tokenizer.tokenize)\n",
    "    # # Tokenize and prepare the corpus\n",
    "    # tokenized_corpus = processor.build_corpus(corpus_documents)\n",
    "    \n",
    "    # print(len(tokenized_corpus))\n",
    "    # # tokenized_corpus = [tweet_tokenizer.tokenize(doc) for doc in corpus_documents]\n",
    "    \n",
    "    # # Initialize BM25 and retrieval model\n",
    "    # bm25_model = BM25Okapi(tokenized_corpus)\n",
    "    \n",
    "    # retrieval_model = BM25Retriever(bm25_model, tokenize_list_tweet)\n",
    "    \n",
    "    encoder_model = SentenceTransformerEncoder(\n",
    "        model_name_or_path='intfloat/e5-large-v2',\n",
    "        query_prompt='query: ',\n",
    "        doc_prompt='passage: ',\n",
    "    )\n",
    "\n",
    "    retrieval_model = DenseRetrieval(\n",
    "        model=encoder_model\n",
    "    )\n",
    "\n",
    "    # Retrieve documents\n",
    "    retrieval_result = finder_task.retrieve(\n",
    "        retriever=retrieval_model,\n",
    "        # top_k=500\n",
    "    )\n",
    "\n",
    "    reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    "    )\n",
    "    reranking_result = finder_task.rerank(\n",
    "                        reranker=reranker,\n",
    "                        results=retrieval_result,\n",
    "                        top_k=100,  # Rerank the top 100 documents\n",
    "                        batch_size=32\n",
    "                    )\n",
    "    \n",
    "    # Save retrieval result\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    file_name = f\"{output_dir}/{task_class}.json\"\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json.dump(retrieval_result, json_file, indent=4)\n",
    "    \n",
    "    # Save evaluation result\n",
    "    df = pd.read_csv(f'../data/{task_class.split(\"_\")[0]}_qrels.tsv', sep='\\t')\n",
    "    qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
    "    \n",
    "    eval_result = finder_task.evaluate(qrels_dict, retrieval_result, [1, 5, 10])\n",
    "    combined_result = {**eval_result[0], **eval_result[1], **eval_result[2], **eval_result[3]}\n",
    "    df_eval = pd.DataFrame([combined_result])\n",
    "    df_eval.to_csv(f'{output_dir}/{task_class.split(\"_\")[0]}_eval.csv', index=False)\n",
    "    \n",
    "    output_dir_ = output_dir+'_'+reranker_name\n",
    "    os.makedirs(output_dir_, exist_ok=True)\n",
    "    file_name = f\"{output_dir_}/{task_class}.json\"\n",
    "    with open(file_name, \"w\") as json_file:\n",
    "        json.dump(reranking_result, json_file, indent=4)\n",
    "    \n",
    "    # Save evaluation result\n",
    "    df = pd.read_csv(f'../data/{task_class.split(\"_\")[0]}_qrels.tsv', sep='\\t')\n",
    "    qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
    "    \n",
    "    eval_result = finder_task.evaluate(qrels_dict, reranking_result, [1, 5, 10])\n",
    "    combined_result = {**eval_result[0], **eval_result[1], **eval_result[2], **eval_result[3]}\n",
    "    df_eval = pd.DataFrame([combined_result])\n",
    "    df_eval.to_csv(f'{output_dir_}/{task_class.split(\"_\")[0]}_eval.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for FinQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 2789 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'd61d9e858', 'title': '', 'text': 'performance graph the performance graph below shows the five-year cumulative total stockholder return on applied common stock during the period from october 25 , 2009 through october 26 , 2014 .\\nthis is compared with the cumulative total return of the standard & poor 2019s 500 stock index and the rdg semiconductor composite index over the same period .\\nthe comparison assumes $ 100 was invested on october 25 , 2009 in applied common stock and in each of the foregoing indices and assumes reinvestment of dividends , if any .\\ndollar amounts in the graph are rounded to the nearest whole dollar .\\nthe performance shown in the graph represents past performance and should not be considered an indication of future performance .\\ncomparison of 5 year cumulative total return* among applied materials , inc. , the s&p 500 index 201cs&p 201d is a registered trademark of standard & poor 2019s financial services llc , a subsidiary of the mcgraw-hill companies , inc. .\\n\\n                                  | 10/25/2009 | 10/31/2010 | 10/30/2011 | 10/28/2012 | 10/27/2013 | 10/26/2014\\n--------------------------------- | ---------- | ---------- | ---------- | ---------- | ---------- | ----------\\napplied materials                 | 100.00     | 97.43      | 101.85     | 88.54      | 151.43     | 183.29    \\ns&p 500 index                     | 100.00     | 116.52     | 125.94     | 145.09     | 184.52     | 216.39    \\nrdg semiconductor composite index | 100.00     | 121.00     | 132.42     | 124.95     | 163.20     | 207.93    \\n\\ndividends during fiscal 2014 , applied 2019s board of directors declared four quarterly cash dividends of $ 0.10 per share each .\\nduring fiscal 2013 , applied 2019s board of directors declared three quarterly cash dividends of $ 0.10 per share each and one quarterly cash dividend of $ 0.09 per share .\\nduring fiscal 2012 , applied 2019s board of directors declared three quarterly cash dividends of $ 0.09 per share each and one quarterly cash dividend of $ 0.08 .\\ndividends declared during fiscal 2014 , 2013 and 2012 totaled $ 487 million , $ 469 million and $ 438 million , respectively .\\napplied currently anticipates that it will continue to pay cash dividends on a quarterly basis in the future , although the declaration and amount of any future cash dividends are at the discretion of the board of directors and will depend on applied 2019s financial condition , results of operations , capital requirements , business conditions and other factors , as well as a determination that cash dividends are in the best interests of applied 2019s stockholders .\\n$ 100 invested on 10/25/09 in stock or 10/31/09 in index , including reinvestment of dividends .\\nindexes calculated on month-end basis .\\nand the rdg semiconductor composite index 183145 97 102 121 132 10/25/09 10/31/10 10/30/11 10/28/12 10/27/13 10/26/14 applied materials , inc .\\ns&p 500 rdg semiconductor composite '}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 1147 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q61676968', 'text': 'what was the average impact on dva of a 1 basis point increase in jpmorgan chase credit spread for 2008 and 2007?'}\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n",
      "Batches: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n",
      "Batches: 100%|██████████| 44/44 [05:44<00:00,  7.83s/it]\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: mps\n",
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n",
      "Batches: 100%|██████████| 3585/3585 [36:12<00:00,  1.65it/s]\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.1948\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.2793\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3055\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.1948\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.2526\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.2633\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.1948\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.3605\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.4419\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.1948\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0721\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0442\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.2413\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.3179\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3497\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.2413\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.2951\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.3082\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.2413\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.3866\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.4855\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.2413\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0773\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0486\n",
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for ConvFinQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 2066 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'dd4bff516', 'title': '', 'text': 'containerboard , kraft papers and saturating kraft .\\nkapstone also owns victory packaging , a packaging solutions distribution company with facilities in the u.s. , canada and mexico .\\nwe have included the financial results of kapstone in our corrugated packaging segment since the date of the acquisition .\\non september 4 , 2018 , we completed the acquisition ( the 201cschl fcter acquisition 201d ) of schl fcter print pharma packaging ( 201cschl fcter 201d ) .\\nschl fcter is a leading provider of differentiated paper and packaging solutions and a german-based supplier of a full range of leaflets and booklets .\\nthe schl fcter acquisition allowed us to further enhance our pharmaceutical and automotive platform and expand our geographical footprint in europe to better serve our customers .\\nwe have included the financial results of the acquired operations in our consumer packaging segment since the date of the acquisition .\\non january 5 , 2018 , we completed the acquisition ( the 201cplymouth packaging acquisition 201d ) of substantially all of the assets of plymouth packaging , inc .\\n( 201cplymouth 201d ) .\\nthe assets we acquired included plymouth 2019s 201cbox on demand 201d systems , which are manufactured by panotec , an italian manufacturer of packaging machines .\\nthe addition of the box on demand systems enhanced our platform , differentiation and innovation .\\nthese systems , which are located on customers 2019 sites under multi-year exclusive agreements , use fanfold corrugated to produce custom , on-demand corrugated packaging that is accurately sized for any product type according to the customer 2019s specifications .\\nfanfold corrugated is continuous corrugated board , folded periodically to form an accordion-like stack of corrugated material .\\nas part of the transaction , westrock acquired plymouth 2019s equity interest in panotec and plymouth 2019s exclusive right from panotec to distribute panotec 2019s equipment in the u.s .\\nand canada .\\nwe have fully integrated the approximately 60000 tons of containerboard used by plymouth annually .\\nwe have included the financial results of plymouth in our corrugated packaging segment since the date of the acquisition .\\nsee 201cnote 3 .\\nacquisitions and investment 201d of the notes to consolidated financial statements for additional information .\\nsee also item 1a .\\n201crisk factors 2014 we may be unsuccessful in making and integrating mergers , acquisitions and investments , and completing divestitures 201d .\\nbusiness .\\n\\n( in millions ) | year ended september 30 , 2019 | year ended september 30 , 2018\\n--------------- | ------------------------------ | ------------------------------\\nnet sales       | $ 18289.0                      | $ 16285.1                     \\nsegment income  | $ 1790.2                       | $ 1707.6                      \\n\\nin fiscal 2019 , we continued to pursue our strategy of offering differentiated paper and packaging solutions that help our customers win .\\nwe successfully executed this strategy in fiscal 2019 in a rapidly changing cost and price environment .\\nnet sales of $ 18289.0 million for fiscal 2019 increased $ 2003.9 million , or 12.3% ( 12.3 % ) , compared to fiscal 2018 .\\nthe increase was primarily due to the kapstone acquisition and higher selling price/mix in our corrugated packaging and consumer packaging segments .\\nthese increases were partially offset by the absence of recycling net sales in fiscal 2019 as a result of conducting the operations primarily as a procurement function beginning in the first quarter of fiscal 2019 , lower volumes , unfavorable foreign currency impacts across our segments compared to the prior year and decreased land and development net sales .\\nsegment income increased $ 82.6 million in fiscal 2019 compared to fiscal 2018 , primarily due to increased corrugated packaging segment income that was partially offset by lower consumer packaging and land and development segment income .\\nthe impact of the contribution from the acquired kapstone operations , higher selling price/mix across our segments and productivity improvements was largely offset by lower volumes across our segments , economic downtime , cost inflation , increased maintenance and scheduled strategic outage expense ( including projects at our mahrt , al and covington , va mills ) and lower land and development segment income due to the wind-down of sales .\\nwith respect to segment income , we experienced higher levels of cost inflation in both our corrugated packaging and consumer packaging segments during fiscal 2019 as compared to fiscal 2018 that were partially offset by recovered fiber deflation .\\nthe primary inflationary items were virgin fiber , freight , energy and wage and other costs .\\nwe generated $ 2310.2 million of net cash provided by operating activities in fiscal 2019 , compared to $ 1931.2 million in fiscal 2018 .\\nwe remained committed to our disciplined capital allocation strategy during fiscal '}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 421 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'qd4982518', 'text': 'what is the price of the s&p 500 index in 2015?'}\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n",
      "Batches: 100%|██████████| 7/7 [00:03<00:00,  2.17it/s]\n",
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n",
      "Batches: 100%|██████████| 33/33 [04:10<00:00,  7.58s/it]\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: mps\n",
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n",
      "Batches: 100%|██████████| 1316/1316 [13:09<00:00,  1.67it/s]\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.1984\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.2913\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3210\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.1984\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.2618\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.2749\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.1984\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.3810\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.4682\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.1984\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0762\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0468\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.2302\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.3428\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3814\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.2302\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.3069\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.3229\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.2302\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.4524\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.5714\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.2302\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0905\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0571\n",
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for MultiHiertt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.common.loader:Loaded 10475 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'd8e4ea4ac', 'title': '', 'text': '|  | Years Ended December 31, |\\n|  | 2006 | 2005 |\\n|  | (In millions) |\\n| Investment return | $192 | $-26 |\\n| Expense | 45 | 11 |\\n| In-force/Persistency | -7 | -33 |\\n| Policyholder dividends and other | -39 | -11 |\\n| Total | $191 | $-59 |\\nAs of December 31, 2006 and 2005, DAC and VOBA for the Individual segment were $14.0 billion and $13.5 billion, respectively, and for the total Company were $20.8 billion and $19.7 billion, respectively.\\nGoodwill Goodwill is the excess of cost over the fair value of net assets acquired.\\nThe Company tests goodwill for impairment at least annually or more frequently if events or circumstances, such as adverse changes in the business climate, indicate that there may be justification for conducting an interim test.\\nImpairment testing is performed using the fair value approach, which requires the use of estimates and judgment, at the \\x80\\x9creporting unit\\x80\\x9d level.\\nA reporting unit is the operating segment or a business that is one level below the operating segment, if discrete financial information is prepared and regularly reviewed by management at that level.\\nFor purposes of goodwill impairment testing, goodwill within Corporate & Other is allocated to reporting units within the Company\\x80\\x99s business segments.\\nIf the carrying value of a reporting unit\\x80\\x99s goodwill exceeds its fair value, the excess is recognized as an impairment and recorded as a charge against net income.\\nThe fair values of the reporting units are determined using a market multiple, a discounted cash flow model, or a cost approach.\\nThe critical estimates necessary in determining fair value are projected earnings, comparative market multiples and the discount rate.\\nLiability for Future Policy Benefits The Company establishes liabilities for amounts payable under insurance policies, including traditional life insurance, traditional annuities and non-medical health insurance.\\nGenerally, amounts are payable over an extended period of time and related liabilities are calculated as the present value of future expected benefits to be paid, reduced by the present value of future expected premiums.\\nSuch liabilities are established based on methods and underlying assumptions in accordance with GAAP and applicable actuarial standards.\\nPrincipal assumptions used in the establishment of liabilities for future policy benefits are mortality, morbidity, policy lapse, renewal, retirement, investment returns, inflation, expenses and other contingent events as appropriate to the respective product type.\\nThese assumptions are established at the time the policy is issued and are intended to estimate the experience for the period the policy benefits are payable.\\nUtilizing these assumptions, liabilities are established on a block of business basis.\\nIf experience is less favorable than assumptions, additional liabilities may be required, resulting in a charge to policyholder benefits and claims.\\nLiabilities for future policy benefits for disabled lives are estimated using the present value of benefits method and experience assumptions as to claim terminations, expenses and interest.\\nLiabilities for unpaid claims and claim expenses for property and casualty insurance are included in future policyholder benefits and represent the amount estimated for claims that have been reported but not settled and claims incurred but not reported.\\nOther policyholder funds include claims that have been reported but not settled and claims incurred but not reported on life and non-medical health insurance.\\nLiabilities for unpaid claims are estimated based upon the Company\\x80\\x99s historical experience and other actuarial assumptions that consider the effects of current developments, anticipated trends and risk management programs.\\nWith respect to property and casualty insurance, such unpaid claims are reduced for anticipated salvage and subrogation.\\nThe effects of changes in such estimated liabilities are included in the results of operations in the period in which the changes occur.\\nFuture policy benefit liabilities for minimum death and income benefit guarantees relating to certain annuity contracts and secondary and paid up guarantees relating to certain life policies are based on estimates of the expected value of benefits in excess of the projected account balance and recognizing the excess ratably over the accumulation period based on total expected assessments.\\nLiabilities for universal and variable life secondary guarantees and paid-up guarantees are determined by estimating the expected value of death benefits payable when the account balance is projected to be zero and recognizing those benefits ratably over the accumulation period'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 974 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q82d4c6ec', 'text': 'What was the sum of Fourth Quarter without those Fourth Quarter smaller than 0, in 2012? (in million)'}\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "INFO:financerag.retrieval.dense:Encoding queries...\n",
      "Batches: 100%|██████████| 16/16 [00:08<00:00,  1.85it/s]\n",
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n",
      "Batches: 100%|██████████| 164/164 [19:48<00:00,  7.24s/it]\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: mps\n",
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n",
      "Batches: 100%|██████████| 3044/3044 [32:03<00:00,  1.58it/s]\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.1336\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.0863\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.0903\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.0335\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.0475\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.0504\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.0335\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.0675\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.0856\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.1336\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0589\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0370\n",
      "/var/folders/7s/bvgzt9qx1mz2fl1nm48s5z3c0000gn/T/ipykernel_27595/2761810980.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n",
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.1918\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.1158\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.1206\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.0455\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.0653\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.0689\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.0455\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.0896\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.1118\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.1918\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.0747\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for task_class in retrieval:\n",
    "    print(f\"Running for {task_class}\")\n",
    "    if task_class in tabular_retrieval:\n",
    "        pass\n",
    "    task_class_obj = getattr(tasks_module, task_class)\n",
    "    finder_task = task_class_obj()\n",
    "\n",
    "    # corpus = pd.read_csv(f\"./data/{task_class}_corpus_convert.csv\")\n",
    "    corpus = load_dataset(\"Linq-AI-Research/FinanceRAG\", task_class, split=\"corpus\")\n",
    "    process_task(task_class, corpus, output_dir, finder_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './e5-large-v2'\n",
    "\n",
    "master_result = pd.DataFrame()\n",
    "for task_class in retrieval:\n",
    "    df_eval = pd.read_csv(f'{output_dir}/{task_class.split(\"_\")[0]}_eval.csv')\n",
    "    df_eval['task'] = task_class\n",
    "    master_result = pd.concat([master_result, df_eval])\n",
    "master_result.to_csv(f'{output_dir}/master_eval.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './e5-large-v2_ms-marco-MiniLM-L-12-v2'\n",
    "master_result = pd.DataFrame()\n",
    "for task_class in retrieval:\n",
    "    df_eval = pd.read_csv(f'{output_dir}/{task_class.split(\"_\")[0]}_eval.csv')\n",
    "    df_eval['task'] = task_class\n",
    "    master_result = pd.concat([master_result, df_eval])\n",
    "master_result.to_csv(f'{output_dir}/master_eval.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>MAP@1</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.24128</td>\n",
       "      <td>0.31790</td>\n",
       "      <td>0.34974</td>\n",
       "      <td>0.24128</td>\n",
       "      <td>0.29511</td>\n",
       "      <td>0.30816</td>\n",
       "      <td>0.24128</td>\n",
       "      <td>0.38663</td>\n",
       "      <td>0.48547</td>\n",
       "      <td>0.24128</td>\n",
       "      <td>0.07733</td>\n",
       "      <td>0.04855</td>\n",
       "      <td>FinQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23016</td>\n",
       "      <td>0.34283</td>\n",
       "      <td>0.38143</td>\n",
       "      <td>0.23016</td>\n",
       "      <td>0.30688</td>\n",
       "      <td>0.32288</td>\n",
       "      <td>0.23016</td>\n",
       "      <td>0.45238</td>\n",
       "      <td>0.57143</td>\n",
       "      <td>0.23016</td>\n",
       "      <td>0.09048</td>\n",
       "      <td>0.05714</td>\n",
       "      <td>ConvFinQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19178</td>\n",
       "      <td>0.11577</td>\n",
       "      <td>0.12063</td>\n",
       "      <td>0.04546</td>\n",
       "      <td>0.06534</td>\n",
       "      <td>0.06893</td>\n",
       "      <td>0.04546</td>\n",
       "      <td>0.08956</td>\n",
       "      <td>0.11182</td>\n",
       "      <td>0.19178</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.04658</td>\n",
       "      <td>MultiHiertt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NDCG@1   NDCG@5  NDCG@10    MAP@1    MAP@5   MAP@10  Recall@1  Recall@5  \\\n",
       "0  0.24128  0.31790  0.34974  0.24128  0.29511  0.30816   0.24128   0.38663   \n",
       "0  0.23016  0.34283  0.38143  0.23016  0.30688  0.32288   0.23016   0.45238   \n",
       "0  0.19178  0.11577  0.12063  0.04546  0.06534  0.06893   0.04546   0.08956   \n",
       "\n",
       "   Recall@10      P@1      P@5     P@10         task  \n",
       "0    0.48547  0.24128  0.07733  0.04855        FinQA  \n",
       "0    0.57143  0.23016  0.09048  0.05714    ConvFinQA  \n",
       "0    0.11182  0.19178  0.07466  0.04658  MultiHiertt  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "      <th>MAP@1</th>\n",
       "      <th>MAP@5</th>\n",
       "      <th>MAP@10</th>\n",
       "      <th>Recall@1</th>\n",
       "      <th>Recall@5</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@5</th>\n",
       "      <th>P@10</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19477</td>\n",
       "      <td>0.27934</td>\n",
       "      <td>0.30548</td>\n",
       "      <td>0.19477</td>\n",
       "      <td>0.25262</td>\n",
       "      <td>0.26330</td>\n",
       "      <td>0.19477</td>\n",
       "      <td>0.36047</td>\n",
       "      <td>0.44186</td>\n",
       "      <td>0.19477</td>\n",
       "      <td>0.07209</td>\n",
       "      <td>0.04419</td>\n",
       "      <td>FinQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.19841</td>\n",
       "      <td>0.29131</td>\n",
       "      <td>0.32099</td>\n",
       "      <td>0.19841</td>\n",
       "      <td>0.26177</td>\n",
       "      <td>0.27487</td>\n",
       "      <td>0.19841</td>\n",
       "      <td>0.38095</td>\n",
       "      <td>0.46825</td>\n",
       "      <td>0.19841</td>\n",
       "      <td>0.07619</td>\n",
       "      <td>0.04683</td>\n",
       "      <td>ConvFinQA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.13356</td>\n",
       "      <td>0.08635</td>\n",
       "      <td>0.09029</td>\n",
       "      <td>0.03354</td>\n",
       "      <td>0.04748</td>\n",
       "      <td>0.05037</td>\n",
       "      <td>0.03354</td>\n",
       "      <td>0.06749</td>\n",
       "      <td>0.08564</td>\n",
       "      <td>0.13356</td>\n",
       "      <td>0.05890</td>\n",
       "      <td>0.03699</td>\n",
       "      <td>MultiHiertt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NDCG@1   NDCG@5  NDCG@10    MAP@1    MAP@5   MAP@10  Recall@1  Recall@5  \\\n",
       "0  0.19477  0.27934  0.30548  0.19477  0.25262  0.26330   0.19477   0.36047   \n",
       "0  0.19841  0.29131  0.32099  0.19841  0.26177  0.27487   0.19841   0.38095   \n",
       "0  0.13356  0.08635  0.09029  0.03354  0.04748  0.05037   0.03354   0.06749   \n",
       "\n",
       "   Recall@10      P@1      P@5     P@10         task  \n",
       "0    0.44186  0.19477  0.07209  0.04419        FinQA  \n",
       "0    0.46825  0.19841  0.07619  0.04683    ConvFinQA  \n",
       "0    0.08564  0.13356  0.05890  0.03699  MultiHiertt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id\\tcorpus_id\\tscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q00001\\tMSFT20230014\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q00001\\tMSFT20230015\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q00007\\tMSFT20231529\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q00008\\tMSFT20231529\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q00010\\tADBE20231571\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>q00197\\tUNH20230438\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>q00200\\tGOOGL20230050\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>q00204\\tGOOGL20230680\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>q00210\\tBRK.A20230396\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>q00212\\tBRK.A20232388\\t1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id\\tcorpus_id\\tscore\n",
       "0      q00001\\tMSFT20230014\\t1\n",
       "1      q00001\\tMSFT20230015\\t1\n",
       "2      q00007\\tMSFT20231529\\t1\n",
       "3      q00008\\tMSFT20231529\\t1\n",
       "4      q00010\\tADBE20231571\\t1\n",
       "..                         ...\n",
       "98      q00197\\tUNH20230438\\t1\n",
       "99    q00200\\tGOOGL20230050\\t1\n",
       "100   q00204\\tGOOGL20230680\\t1\n",
       "101   q00210\\tBRK.A20230396\\t1\n",
       "102   q00212\\tBRK.A20232388\\t1\n",
       "\n",
       "[103 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('../data/FinDER_qrels.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financerag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
